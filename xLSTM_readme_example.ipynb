{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "\n",
    "sys.path.append('../..')\n",
    "from omegaconf import OmegaConf\n",
    "from pprint import pprint\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "import torch\n",
    "\n",
    "from xlstm.xlstm_block_stack import xLSTMBlockStack, xLSTMBlockStackConfig\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xLSTM Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-LC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.6\\\\lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\Admin\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\Admin\\AppData\\Local\\torch_extensions\\torch_extensions\\Cache\\py311_cu118\\slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0\\build.ninja...\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\dfine\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'distutils' has no attribute '_msvccompiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m cfg \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mcreate(xlstm_cfg)\n\u001b[0;32m     22\u001b[0m cfg \u001b[38;5;241m=\u001b[39m from_dict(data_class\u001b[38;5;241m=\u001b[39mxLSTMBlockStackConfig, data\u001b[38;5;241m=\u001b[39mOmegaConf\u001b[38;5;241m.\u001b[39mto_container(cfg), config\u001b[38;5;241m=\u001b[39mDaciteConfig(strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m---> 23\u001b[0m xlstm_stack \u001b[38;5;241m=\u001b[39m \u001b[43mxLSTMBlockStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\xlstm_block_stack.py:84\u001b[0m, in \u001b[0;36mxLSTMBlockStack.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39madd_post_blocks_norm:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_blocks_norm \u001b[38;5;241m=\u001b[39m LayerNorm(ndim\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dim)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\xlstm_block_stack.py:105\u001b[0m, in \u001b[0;36mxLSTMBlockStack._create_blocks\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    103\u001b[0m         config\u001b[38;5;241m.\u001b[39m_block_idx \u001b[38;5;241m=\u001b[39m block_idx\n\u001b[0;32m    104\u001b[0m         config\u001b[38;5;241m.\u001b[39m__post_init__()\n\u001b[1;32m--> 105\u001b[0m     blocks\u001b[38;5;241m.\u001b[39mappend(\u001b[43msLSTMBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid block type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock_type_int\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\block.py:33\u001b[0m, in \u001b[0;36msLSTMBlock.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: sLSTMBlockConfig):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxLSTMBlockConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmlstm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mslstm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslstm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeedforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeedforward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_block_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_num_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_blocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\xlstm_block.py:63\u001b[0m, in \u001b[0;36mxLSTMBlock.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxlstm \u001b[38;5;241m=\u001b[39m mLSTMLayer(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmlstm)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mslstm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxlstm \u001b[38;5;241m=\u001b[39m \u001b[43msLSTMLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslstm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither mlstm or slstm must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\layer.py:78\u001b[0m, in \u001b[0;36msLSTMLayer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzgate \u001b[38;5;241m=\u001b[39m LinearHeadwiseExpand(\n\u001b[0;32m     64\u001b[0m     config\u001b[38;5;241m=\u001b[39mLinearHeadwiseExpandConfig(\n\u001b[0;32m     65\u001b[0m         in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mogate \u001b[38;5;241m=\u001b[39m LinearHeadwiseExpand(\n\u001b[0;32m     71\u001b[0m     config\u001b[38;5;241m=\u001b[39mLinearHeadwiseExpandConfig(\n\u001b[0;32m     72\u001b[0m         in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslstm_cell \u001b[38;5;241m=\u001b[39m \u001b[43msLSTMCell\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_norm \u001b[38;5;241m=\u001b[39m MultiHeadLayerNorm(\n\u001b[0;32m     80\u001b[0m     ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dim, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgroup_norm_weight\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdropout)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\cell.py:780\u001b[0m, in \u001b[0;36msLSTMCell.__new__\u001b[1;34m(cls, config, skip_backend_init)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config: sLSTMCellConfig, skip_backend_init: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 780\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msLSTMCell_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_backend_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_backend_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sLSTMCell_vanilla(config)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\cell.py:690\u001b[0m, in \u001b[0;36msLSTMCell_cuda.__init__\u001b[1;34m(self, config, skip_backend_init)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSBNGH\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_backend_init:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m \u001b[43msLSTMCellFuncGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\cell.py:536\u001b[0m, in \u001b[0;36msLSTMCellFuncGenerator\u001b[1;34m(training, config)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msLSTMCellFuncGenerator\u001b[39m(training, config: sLSTMCellConfig):\n\u001b[1;32m--> 536\u001b[0m     slstm_cuda \u001b[38;5;241m=\u001b[39m \u001b[43msLSTMCellCUDA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     slstm_mod \u001b[38;5;241m=\u001b[39m slstm_cuda\u001b[38;5;241m.\u001b[39msLSTMFunc(\n\u001b[0;32m    538\u001b[0m         training, config\u001b[38;5;241m.\u001b[39mbatch_size, config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mnum_heads\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01msLSTMCellFunction\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mFunction):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\cell.py:515\u001b[0m, in \u001b[0;36msLSTMCellCUDA.instance\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config: sLSTMCellConfig):\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mrepr\u001b[39m(config) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmod:\n\u001b[1;32m--> 515\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmod[\u001b[38;5;28mrepr\u001b[39m(config)] \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslstm.cc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslstm_forward.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslstm_backward.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslstm_backward_cut.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_pointwise.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutil\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblas.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutil\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda_error.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-D\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconst\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconstval\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    528\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmod[\u001b[38;5;28mrepr\u001b[39m(config)]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Desktop\\xlstm\\xlstm\\xlstm\\blocks\\slstm\\src\\cuda_init.py:84\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     83\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore compilation and loading of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmyargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter compilation and loading of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\dfine\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1309\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[0;32m   1218\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   1219\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1227\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1228\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\dfine\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1719\u001b[0m, in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[0;32m   1717\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[1;32m-> 1719\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1731\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\dfine\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:1832\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[0;32m   1830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m   1831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m-> 1832\u001b[0m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError building extension \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\dfine\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:2084\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[1;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[0;32m   2081\u001b[0m plat_name \u001b[38;5;241m=\u001b[39m distutils\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_platform()\n\u001b[0;32m   2082\u001b[0m plat_spec \u001b[38;5;241m=\u001b[39m PLAT_TO_VCVARS[plat_name]\n\u001b[1;32m-> 2084\u001b[0m vc_env \u001b[38;5;241m=\u001b[39m \u001b[43mdistutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_msvccompiler\u001b[49m\u001b[38;5;241m.\u001b[39m_get_vc_env(plat_spec)\n\u001b[0;32m   2085\u001b[0m vc_env \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mupper(): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m vc_env\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'distutils' has no attribute '_msvccompiler'"
     ]
    }
   ],
   "source": [
    "xlstm_cfg = f\"\"\" \n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'} #! only vanilla here works\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 256\n",
    "num_blocks: 7\n",
    "embedding_dim: 128\n",
    "slstm_at: [1] #[1] # for [] it also works, so if no sLSTM is in the stack\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMBlockStack(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xLSTMBlockStackConfig(mlstm_block=mLSTMBlockConfig(mlstm=mLSTMLayerConfig(proj_factor=2.0,\n",
      "                                                                          round_proj_up_dim_up=True,\n",
      "                                                                          round_proj_up_to_multiple_of=64,\n",
      "                                                                          _proj_up_dim=256,\n",
      "                                                                          conv1d_kernel_size=4,\n",
      "                                                                          qkv_proj_blocksize=4,\n",
      "                                                                          num_heads=4,\n",
      "                                                                          embedding_dim=128,\n",
      "                                                                          bias=False,\n",
      "                                                                          dropout=0.0,\n",
      "                                                                          context_length=256,\n",
      "                                                                          _num_blocks=7,\n",
      "                                                                          _inner_embedding_dim=256)),\n",
      "                      slstm_block=sLSTMBlockConfig(slstm=sLSTMLayerConfig(hidden_size=128,\n",
      "                                                                          num_heads=4,\n",
      "                                                                          num_states=4,\n",
      "                                                                          backend='vanilla',\n",
      "                                                                          function='slstm',\n",
      "                                                                          bias_init='powerlaw_blockdependent',\n",
      "                                                                          recurrent_weight_init='zeros',\n",
      "                                                                          _block_idx=0,\n",
      "                                                                          _num_blocks=7,\n",
      "                                                                          num_gates=4,\n",
      "                                                                          gradient_recurrent_cut=False,\n",
      "                                                                          gradient_recurrent_clipval=None,\n",
      "                                                                          forward_clipval=None,\n",
      "                                                                          batch_size=8,\n",
      "                                                                          input_shape='BSGNH',\n",
      "                                                                          internal_input_shape='SBNGH',\n",
      "                                                                          output_shape='BNSH',\n",
      "                                                                          constants={},\n",
      "                                                                          dtype='bfloat16',\n",
      "                                                                          dtype_b='float32',\n",
      "                                                                          dtype_r='bfloat16',\n",
      "                                                                          dtype_w='bfloat16',\n",
      "                                                                          dtype_g='bfloat16',\n",
      "                                                                          dtype_s='bfloat16',\n",
      "                                                                          dtype_a='float32',\n",
      "                                                                          enable_automatic_mixed_precision=True,\n",
      "                                                                          initial_val=0.0,\n",
      "                                                                          embedding_dim=128,\n",
      "                                                                          conv1d_kernel_size=4,\n",
      "                                                                          group_norm_weight=True,\n",
      "                                                                          dropout=0.0),\n",
      "                                                   feedforward=FeedForwardConfig(proj_factor=1.3,\n",
      "                                                                                 round_proj_up_dim_up=True,\n",
      "                                                                                 round_proj_up_to_multiple_of=64,\n",
      "                                                                                 _proj_up_dim=0,\n",
      "                                                                                 act_fn='gelu',\n",
      "                                                                                 embedding_dim=-1,\n",
      "                                                                                 dropout=0.0,\n",
      "                                                                                 bias=False,\n",
      "                                                                                 ff_type='ffn_gated',\n",
      "                                                                                 _num_blocks=1),\n",
      "                                                   _num_blocks=7,\n",
      "                                                   _block_idx=0),\n",
      "                      context_length=256,\n",
      "                      num_blocks=7,\n",
      "                      embedding_dim=128,\n",
      "                      add_post_blocks_norm=True,\n",
      "                      bias=False,\n",
      "                      dropout=0.0,\n",
      "                      slstm_at=[1],\n",
      "                      _block_map='0,1,0,0,0,0,0')\n"
     ]
    }
   ],
   "source": [
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xLSTMBlockStack(\n",
       "  (blocks): ModuleList(\n",
       "    (0): mLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): mLSTMLayer(\n",
       "        (proj_up): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (q_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (k_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (v_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (mlstm_cell): mLSTMCell(\n",
       "          (igate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (fgate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (outnorm): MultiHeadLayerNorm()\n",
       "        )\n",
       "        (ogate_act_fn): SiLU()\n",
       "        (proj_down): Linear(in_features=256, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): sLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): sLSTMLayer(\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (fgate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (igate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (zgate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (ogate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (slstm_cell): sLSTMCell_vanilla(function=slstm, hidden_size=128, num_heads=4)\n",
       "        (group_norm): MultiHeadLayerNorm()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn_norm): LayerNorm()\n",
       "      (ffn): GatedFeedForward(\n",
       "        (proj_up): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (proj_down): Linear(in_features=192, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2-6): 5 x mLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): mLSTMLayer(\n",
       "        (proj_up): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (q_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (k_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (v_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (mlstm_cell): mLSTMCell(\n",
       "          (igate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (fgate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (outnorm): MultiHeadLayerNorm()\n",
       "        )\n",
       "        (ogate_act_fn): SiLU()\n",
       "        (proj_down): Linear(in_features=256, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_blocks_norm): LayerNorm()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlstm_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4, 256, 128).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "xlstm_stack = xlstm_stack.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "y = xlstm_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readme example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from xlstm import xLSTMBlockStack, xLSTMBlockStackConfig\n",
    "\n",
    "xlstm_cfg = f\"\"\" \n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'}\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 256\n",
    "num_blocks: 7\n",
    "embedding_dim: 128\n",
    "slstm_at: [1]\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMBlockStack(cfg)\n",
    "\n",
    "x = torch.randn(4, 256, 128).to(device=device)\n",
    "xlstm_stack = xlstm_stack.to(device=device)\n",
    "y = xlstm_stack(x)\n",
    "y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from xlstm import (\n",
    "    xLSTMBlockStack,\n",
    "    xLSTMBlockStackConfig,\n",
    "    mLSTMBlockConfig,\n",
    "    mLSTMLayerConfig,\n",
    "    sLSTMBlockConfig,\n",
    "    sLSTMLayerConfig,\n",
    "    FeedForwardConfig,\n",
    ")\n",
    "\n",
    "cfg = xLSTMBlockStackConfig(\n",
    "    mlstm_block=mLSTMBlockConfig(\n",
    "        mlstm=mLSTMLayerConfig(\n",
    "            conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=4\n",
    "        )\n",
    "    ),\n",
    "    slstm_block=sLSTMBlockConfig(\n",
    "        slstm=sLSTMLayerConfig(\n",
    "            backend=\"cuda\" if torch.cuda.isavailable() else \"vanilla\",\n",
    "            num_heads=4,\n",
    "            conv1d_kernel_size=4,\n",
    "            bias_init=\"powerlaw_blockdependent\",\n",
    "        ),\n",
    "        feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"),\n",
    "    ),\n",
    "    context_length=256,\n",
    "    num_blocks=7,\n",
    "    embedding_dim=128,\n",
    "    slstm_at=[1],\n",
    "\n",
    ")\n",
    "\n",
    "xlstm_stack = xLSTMBlockStack(cfg)\n",
    "\n",
    "x = torch.randn(4, 256, 128).to(device=device)\n",
    "xlstm_stack = xlstm_stack.to(device=device)\n",
    "y = xlstm_stack(x)\n",
    "y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from xlstm.xlstm_block_stack import xLSTMBlockStack, xLSTMBlockStackConfig\n",
    "\n",
    "xlstm_cfg = f\"\"\" \n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'}\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 256\n",
    "num_blocks: 7\n",
    "embedding_dim: 128\n",
    "slstm_at: [] #[1]\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMBlockStack(cfg)\n",
    "\n",
    "x = torch.randn(4, 256, 128).to(device=device)\n",
    "xlstm_stack = xlstm_stack.to(device=device)\n",
    "y = xlstm_stack(x)\n",
    "y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from xlstm.xlstm_lm_model import xLSTMLMModel, xLSTMLMModelConfig\n",
    "\n",
    "xlstm_cfg = f\"\"\" \n",
    "vocab_size: 50304\n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'}\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 256\n",
    "num_blocks: 7\n",
    "embedding_dim: 128\n",
    "slstm_at: [] #[1]\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMLMModelConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMLMModel(cfg)\n",
    "\n",
    "x = torch.randint(0, 50304, size=(4, 256)).to(device=device)\n",
    "xlstm_stack = xlstm_stack.to(device)\n",
    "y = xlstm_stack(x)\n",
    "y.shape[1:] == (256, 50304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
